{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable(\"vegafusion\") # so that Altair would not complain over too large dataset\n",
    "\n",
    "# Read and format the data\n",
    "hw = pd.read_csv('./data/height_weight_gender.csv')\n",
    "hw.Height*=100\n",
    "hw.replace({0: 'Male', 1: 'Female'}, inplace=True)\n",
    "hw.columns = hw.columns.str.lower()\n",
    "\n",
    "print(hw.head())\n",
    "print(hw.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom into height and weight. \n",
    "\n",
    "They both are normally distributed, so let's use Gaussian as our priors -- and let's keep things simple and get the parameters from the data (and yes, we did say in teh seminar that this is what you should not do in general). But the next step is also silly anyway :)\n",
    "\n",
    "We then first sample from both distributions *independently*, combine results into a dataframe and visualise it as scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution means and standard deviations for height and weight from the data\n",
    "mean_h, sigma_h = hw.height.mean(), hw.height.std()\n",
    "mean_w, sigma_w = hw.weight.mean(), hw.weight.std()\n",
    "\n",
    "# number of draws\n",
    "n = 5000\n",
    "\n",
    "# Generate random samples\n",
    "h_values = np.random.normal(mean_h, sigma_h, n)\n",
    "w_values = np.random.normal(mean_w, sigma_w, n)\n",
    "\n",
    "# Create the simulation dataframe\n",
    "df_sim = pd.DataFrame({'height': h_values, 'weight': w_values})\n",
    "\n",
    "alt.Chart(df_sim).mark_circle(size=7, opacity=0.5).encode(\n",
    "    x=alt.X('weight').scale(domain=[20, 130]),\n",
    "    y=alt.Y('height').scale(domain=[130,210])\n",
    ").properties(height=400, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is what the data would look like if height and weight was not related. But of course we know that it in fact is. If we sample the actual data we see that it looks like we would expect it to -- there is a strong relationship and in order to visualise and quantify it we can fit a regression, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base for plots\n",
    "base = alt.Chart(hw).properties(\n",
    "    width=400,\n",
    "    height=400\n",
    ") \n",
    "\n",
    "# Create scatter plot of weights and heights in the data\n",
    "points = base.mark_circle(size=5, opacity=0.3).encode(\n",
    "    alt.X('weight:Q').scale(domain=[25,125]),\n",
    "    alt.Y('height:Q').scale(domain=[120,220]),\n",
    "     tooltip=['height', 'weight']\n",
    ").properties(height=400, width=400)\n",
    "\n",
    "# ... and fit linear regression to see the relationship\n",
    "(points + points.transform_regression('weight', 'height').mark_line(color='orange', size=1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's take a step back and first isolate height and plot the actual distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = base.mark_bar(opacity=0.75, thickness=100).encode(\n",
    "    alt.X('height')\n",
    "        .bin(step=5) \n",
    "        .scale(domain=[120, 220])\n",
    "        .title(None),\n",
    "    alt.Y('count()')\n",
    "        .stack(None)\n",
    "        .title(None)\n",
    "        .axis(None),\n",
    ").properties(height=300, width=400)\n",
    "\n",
    "p.show()\n",
    "\n",
    "print(f'std: {hw.height.std():.2f}, mean: {hw.height.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the height distribution is normal. So we can create a Gaussian PDF function that will return a dataframe \n",
    "of values for a given mean and standard deviation in order to generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gaussian_pdf(mean, sigma):\n",
    "\n",
    "    # Create a range of x values for heights\n",
    "    x_values = np.linspace(mean - 4*sigma, mean + 4*sigma, 500)\n",
    "\n",
    "    # Calculate the corresponding y values for the Gaussian PDF\n",
    "    y_values = (1/(sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x_values - mean)/sigma)**2)\n",
    "\n",
    "    # Return a dataframe of PDF values\n",
    "    return pd.DataFrame({\n",
    "        'x': x_values,\n",
    "        'y': y_values\n",
    "    })\n",
    "\n",
    "mean = 168.6\n",
    "sigma = 9.8\n",
    "\n",
    "chart = alt.Chart(gaussian_pdf(mean, sigma)).mark_line(color='red').encode(\n",
    "    x=alt.X('x', title='x'),\n",
    "    y=alt.Y('y', title='Probability Density')\n",
    "    .scale(domain=[0, 0.04])\n",
    ").properties(\n",
    "    title=f\"Gaussian PDF (μ={mean}, σ={sigma})\",\n",
    "    width=400\n",
    ")\n",
    "\n",
    "# Check the fit\n",
    "(p + chart).resolve_scale(y='independent')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty decent fit, so let's go on and plot the actual data along with the marginal distributions of both height and weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist_x = base.mark_bar(opacity=0.75, thickness=100, orient='horizontal').encode(\n",
    "    alt.X('weight')\n",
    "        .bin(step=5) # step keeps bin size the same\n",
    "        .scale(domain=[25,125]).axis(None),\n",
    "    alt.Y('count()')\n",
    "        .stack(None)\n",
    "        .axis(None)\n",
    ").properties(height=70, width=400)\n",
    "\n",
    "hist_y = base.mark_bar(opacity=0.75, thickness=100).encode(\n",
    "    alt.Y('height')\n",
    "        .bin(step=5)\n",
    "        .scale(domain=[120, 220])\n",
    "        .axis(None),\n",
    "    alt.X('count()')\n",
    "        .stack(None)\n",
    "        .axis(None),\n",
    ").properties(width=70, height=400)\n",
    "\n",
    "(hist_x & (points + points.transform_regression('weight', 'height').mark_line(color='orange', size=1.5) | hist_y)).configure_axis(\n",
    "        title=None).configure_view(strokeWidth=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight distribution looks suspicious, let's isolate and plot it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = base.mark_bar(opacity=0.75, thickness=100, orient='horizontal').encode(\n",
    "    alt.X('weight')\n",
    "        .bin(step=5) \n",
    "        .scale(domain=[25,125]),\n",
    "    alt.Y('count()')\n",
    "        .stack(None)\n",
    "        .axis(None)\n",
    ")\n",
    "\n",
    "p.show()\n",
    "\n",
    "print(f'std: {hw.weight.std():.2f}, mean: {hw.weight.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly not normal, but let's try to fit a Gaussian distribution to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean = hw.weight.mean()\n",
    "sigma = hw.weight.std()\n",
    "\n",
    "chart = alt.Chart(gaussian_pdf(mean, sigma)).mark_line(color='red').encode(\n",
    "    x=alt.X('x', title='weight'),\n",
    "    y=alt.Y('y', title='Probability Density')\n",
    ").properties(\n",
    "    title=f\"Gaussian PDF (μ={mean:.2f}, σ={sigma:.2f})\"\n",
    ")\n",
    "\n",
    "(p + chart).resolve_scale(y='independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not atrocious, the fit is not very good -- and of course in this particular case we can tell very easily that the actual distrbution of values is bimodal, and we can also tell easily what's the issue. So let's stratify the data by gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(hw.groupby('gender').weight.mean(),'\\n')\n",
    "print(hw.groupby('gender').weight.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and fit a separate Gaussian distribution to each gender.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_f, mean_m = hw.groupby('gender').weight.mean()\n",
    "sigma_f, sigma_m = hw.groupby('gender').weight.std()\n",
    "\n",
    "chart_f = alt.Chart(gaussian_pdf(mean_f, sigma_f)).mark_line(color='red').encode(\n",
    "    x=alt.X('x').title('weight'),\n",
    "    y=alt.Y('y').title('stratified pdf')\n",
    ")\n",
    "\n",
    "chart_m = alt.Chart(gaussian_pdf(mean_m, sigma_m)).mark_line(color='lightblue').encode(\n",
    "    x=alt.X('x'),\n",
    "    y=alt.Y('y').scale(domain=[0, 0.05]).axis(None)\n",
    ").properties(\n",
    "    #title=f\"Gaussian PDF (μ={mean}, σ={sigma})\"\n",
    ")\n",
    "\n",
    "((p + chart_f + chart_m).resolve_scale(y='independent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there we are, that did it. In order to fit a single distribution we next create a mixture of two Gaussians.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Acquire gender proportions from the data\n",
    "weights = hw.gender.value_counts(normalize=True)\n",
    "\n",
    "# Weights for the mixture\n",
    "w1, w2 = weights.Female, weights.Male  # Get gender weights from the sample\n",
    "\n",
    "# Generate 500 x values between 30 and 120\n",
    "x = np.linspace(30, 120, 500)\n",
    "\n",
    "# Compute PDFs for both Gaussians\n",
    "pdf1 = norm.pdf(x, mean_f, sigma_f)\n",
    "pdf2 = norm.pdf(x, mean_m, sigma_m)\n",
    "\n",
    "# Compute mixture\n",
    "pdf_mixture = w1 * pdf1 + w2 * pdf2\n",
    "\n",
    "gmm_df = pd.DataFrame({\n",
    "    'weight': np.concatenate([x, x, x]),\n",
    "    'pdf': np.concatenate([pdf1, pdf2, pdf_mixture]),\n",
    "    'distribution': [f'Gaussian: μ={mean_f:.1f}, σ={sigma_f:.1f}'] * len(x) + [f'Gaussian: μ={mean_m:.1f}, σ={sigma_m:.1f}'] * len(x) + ['Mixture'] * len(x)\n",
    "})\n",
    "\n",
    "# Plot both gaussians and mixture\n",
    "gmm = alt.Chart(gmm_df).mark_line().encode(\n",
    "    x='weight',\n",
    "    y='pdf',\n",
    "    color='distribution:N' \n",
    ").properties(\n",
    "    title=\"Mixture of Two Gaussians\",\n",
    "    width=400,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "gmm.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and next fit it to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gmm = alt.Chart(gmm_df[gmm_df.distribution=='Mixture'], title='Fit with Gaussian mixture').mark_line(color='red').encode(\n",
    "    x=alt.X('weight:Q').title('weight'),\n",
    "    y=alt.Y('pdf:Q').scale(domain=[0, 0.025])\n",
    ")\n",
    "((p + gmm).resolve_scale(y='independent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So voilà, we have a mixture model that fits the data well.\n",
    "Let's plot the data again, this time with both marginal distributions stratified by gender and the fit separate regression lines for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = alt.selection_point(fields=['gender'])\n",
    "\n",
    "color_scale = alt.Scale(domain=['Male', 'Female'],\n",
    "                        range=['black', 'red']\n",
    "                        )\n",
    "\n",
    "base = alt.Chart(hw).properties(height=400, width=400).add_params(selector)\n",
    "\n",
    "points = base.mark_point(filled=True, size=5, opacity=0.3).encode(\n",
    "    alt.X('weight:Q').scale(domain=[25,125]),\n",
    "    alt.Y('height:Q').scale(domain=[120,220]),\n",
    "    color=alt.condition(\n",
    "        selector,\n",
    "        'gender:N',\n",
    "        alt.value('lightgray'),\n",
    "        scale=color_scale),\n",
    ")\n",
    "\n",
    "hist_x = base.mark_bar(opacity=0.5, thickness=100, orient='horizontal').encode(\n",
    "    alt.X('weight')\n",
    "        .bin(step=5) # step keeps bin size the same\n",
    "        .scale(domain=[25,125]).axis(None),\n",
    "    alt.Y('count()')\n",
    "        .stack(None)\n",
    "        .axis(None),\n",
    "     alt.Color('gender:N').scale(color_scale).legend(title=None, orient='bottom')\n",
    ").transform_filter(\n",
    "    selector\n",
    ").properties(height=65, width=400)\n",
    "\n",
    "hist_y = base.mark_bar(opacity=0.5, thickness=100).encode(\n",
    "    alt.Y('height')\n",
    "        .bin(step=5) # step keeps bin size the same\n",
    "        .scale(domain=[120, 220]).axis(None),\n",
    "    alt.X('count()')\n",
    "        .stack(None)\n",
    "        .axis(None),\n",
    "     alt.Color('gender:N').scale(color_scale)\n",
    ").transform_filter(\n",
    "    selector\n",
    ").properties(width=65, height=400)\n",
    "\n",
    "(hist_x & (points + points.transform_regression('weight', 'height', groupby=['gender']).mark_line(size=1)| hist_y)).configure_axis(\n",
    "        title=None).configure_view(strokeWidth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we go, we have created a really simple (not actually bayesian) conceptual generative model that would produce the data that we observed -- and that we can sample for any number of observations. So next we will turn to how to actually make it work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
