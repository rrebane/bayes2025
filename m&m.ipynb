{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd38f514-c06b-473d-960e-6f3e760d903f",
   "metadata": {},
   "source": [
    "## M&M MODEL\n",
    "\n",
    "Let's load libraries and observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d308208-f70b-4524-b73e-6f42ce629e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "#az.style.use(\"arviz-doc\")\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# loading the data\n",
    "df = pd.read_csv('./data/Counting Candies_ M&M with Bayes.csv.zip').drop('Timestamp', axis=1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# let's translate this to a binomial sample \n",
    "blue = df.Blue.sum()\n",
    "total = df.sum().sum()\n",
    "sample = np.concatenate((np.repeat(1, blue), np.repeat(0, total - blue)))\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c276f0-cd4b-4fd4-a636-e0c875a8179f",
   "metadata": {},
   "source": [
    "#### Prior\n",
    "\n",
    "Let's simulate our prior belief on the assumption that the color distribution is uniform and model the proportion of blue candies. For this we draw 1000 samples equal to the size of our observations from the binomial distribution and calculate the proporton of color==blue in each simulated sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b5faf-a252-4f2d-a8cd-1edeb6e1008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prior = np.random.binomial(total, 1/6, 1000) / total\n",
    "\n",
    "data = pd.DataFrame(prior, columns=['p'])\n",
    "\n",
    "data.plot.kde()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4305ad8-cd5d-4636-866f-9b61e28e3bf1",
   "metadata": {},
   "source": [
    "Next we construct a model that will sample a Bernoulli distribution on the basis of our observations. We will set a *flat prior* (pm.Uniform) on the proportion of blue color, allowing it to vary from 0 to 1. By doing this we express indifference towards the actual color distribution -- we deem it equally likely that there may be no blue candies in the sample, or that all the candies in the sample might be blue -- or that every 6th candy would be blue.\n",
    "\n",
    "pm.Uniform is an uninformative prior that gives the model maximum flexibility. As a general rule we can actually do better and choose more informative priors, based on our existing knowledge -- and indeed, as we shall see, often there are many different priors that can be chosen for a particular problem. However, since we are dealing with a very simple problem these considerations do not play a major part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0d939-d6d5-4559-8201-02a53849ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pm.Model() as mm_model:\n",
    "    p = pm.Uniform('p', lower=0, upper=1)\n",
    "    y = pm.Bernoulli('y', p=p, observed=sample)\n",
    "    \n",
    "pm.model_to_graphviz(mm_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e1a44f-557a-4fa5-9c23-fc17402828ce",
   "metadata": {},
   "source": [
    "Next it is generally a good idea to run a prior predictive check to see what does our model do *before* it has seen any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mm_model:\n",
    "    pp = pm.sample_prior_predictive()\n",
    "\n",
    "print(pp.prior.p)\n",
    "\n",
    "alt.Chart(pd.DataFrame(pp.prior.p[0], columns=['p'])).mark_tick().encode(\n",
    "    x='p'\n",
    ").properties(width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b2d16",
   "metadata": {},
   "source": [
    "OK, everything is as expected, so we're ready to push the button and run the model with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d8c25-62d8-4fc0-b838-551caefadc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mm_model:\n",
    "    trace = pm.sample()\n",
    "\n",
    "pm.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb22c5-8f22-483d-8efc-21a01cf7b68d",
   "metadata": {},
   "source": [
    "Next we check the model run diagnostics (a lot more about that later) and plot the posterior distribution against the reference value of 1/6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd38e0-2ca2-4e6c-8db8-79bae4e9e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm.summary(trace))\n",
    "\n",
    "az.plot_posterior(trace, ref_val=(1/6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6387ef-4f15-4cbe-b946-f5796aa37cc1",
   "metadata": {},
   "source": [
    "Let's look at prior and posterior comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031facb-bfad-49ef-abd6-55c129a96f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prior_plot = alt.Chart(data).transform_density(\n",
    "    'p',\n",
    "    as_=['p', 'density'],\n",
    "    #bandwidth = 0.05\n",
    ").mark_area(opacity=0.5).encode(\n",
    "    x=\"p:Q\",\n",
    "    y='density:Q',\n",
    ")\n",
    "\n",
    "\n",
    "post_plot = alt.Chart(pd.DataFrame(trace.posterior.p[0], columns=['p']), width=400).transform_density(\n",
    "    'p',\n",
    "    as_=['p', 'density'],\n",
    "    #bandwidth = 0.05\n",
    ").mark_area(opacity=0.5, color='pink').encode(\n",
    "    x=\"p:Q\",\n",
    "    y='density:Q',\n",
    ")\n",
    "\n",
    "post_plot + prior_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def posterior_grid(grid=10, a=1, b=1, blue=5, trials=20):\n",
    "    grid_vals = np.linspace(0, 1, grid)\n",
    "    prior = stats.beta(a,b).pdf(grid_vals) #stats.beta(a, b).pdf(grid_vals)\n",
    "    likelihood = stats.binom.pmf(blue, trials, grid_vals)\n",
    "    posterior = likelihood * prior\n",
    "    posterior /= posterior.sum()\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        \"Probability\": np.tile(grid_vals, 3),\n",
    "        \"Density\": np.concatenate([prior, likelihood, posterior]),\n",
    "        \"Type\": np.repeat([\"Prior\", \"Likelihood\", \"Posterior\"], grid)\n",
    "    })\n",
    "    \n",
    "    chart = alt.Chart(data).mark_line(point=True).encode(\n",
    "        x=alt.X(\"Probability\", title=\"p(Blue)\"),\n",
    "        y=alt.Y(\"Density\", title=\"Density\"),\n",
    "        color=alt.Color(\"Type\").legend(None),\n",
    "        facet=alt.Facet(\"Type:N\", columns=3, sort=[\"Prior\", \"Likelihood\", \"Posterior\"]).title(None),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('Probability', format='.2%'), \n",
    "            alt.Tooltip('Density', format='.2f')]\n",
    "    ).properties(\n",
    "        width=250,\n",
    "        height=200,\n",
    "        title=f\"Blue = {blue}, Trials = {trials}\"\n",
    "    ).resolve_scale(y=\"independent\")\n",
    "    \n",
    "    return chart\n",
    "\n",
    "posterior_grid(grid=10, blue=1, trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d29e11-a97f-49e9-9807-770777875dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "figsize(11, 7)\n",
    "\n",
    "dist = stats.beta\n",
    "n_trials = [0, 1, 2, 3, 4, 5, 20, 50, 500]\n",
    "data = stats.bernoulli.rvs(trace.posterior.p.mean(), size=n_trials[-1])\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "for k, N in enumerate(n_trials):\n",
    "    sx = plt.subplot(len(n_trials)//2, 3, k+1)\n",
    "    plt.xlabel(\"$p$, probability of blue candy\") \\\n",
    "        if k in [0, len(n_trials)-1] else None\n",
    "    plt.setp(sx.get_yticklabels(), visible=False)\n",
    "    heads = data[:N].sum()\n",
    "    y = dist.pdf(x, 1 + heads, 1 + N - heads)\n",
    "    plt.plot(x, y, label=\"%d candies taken,\\n %d of them blue\" % (N, heads))\n",
    "    plt.fill_between(x, 0, y, color=\"#348ABD\", alpha=0.4)\n",
    "    plt.vlines(0.5, 0, 4, color=\"k\", linestyles=\"--\", lw=1)\n",
    "\n",
    "    leg = plt.legend()\n",
    "    leg.get_frame().set_alpha(0.4)\n",
    "    plt.autoscale(tight=True)\n",
    "\n",
    "\n",
    "plt.suptitle(\"Bayesian updating of posterior probability\",\n",
    "             y=1.02,\n",
    "             fontsize=14)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
